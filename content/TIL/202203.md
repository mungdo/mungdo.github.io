---
emoji: 🌈
title: "202203"
date: '2022-03-01 16:30:00'
author: mungdo
tags: til
categories: til
---


__👋 매일 공부 기록__


## 🥺 20220301

__<알고리즘>__

[깃허브 업로드1](https://github.com/mungdo/mungdo/blob/main/algorithm/special%20lecture/8_%EA%B7%B8%EB%9E%98%ED%94%84%ED%83%90%EC%83%89.py)
[깃허브 업로드2](https://github.com/mungdo/mungdo/blob/main/algorithm/special%20lecture/9_%EA%B7%B8%EB%9E%98%ED%94%84%ED%83%90%EC%83%89_%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4.py)

[블로그 포스팅](https://mungdo-log.tistory.com/377)

* 그래프 탐색
    * DFS
    * BFS



---

## ⚙️ 20220302

__<머신러닝 : 지도학습 knn(회귀, 분류)>__

[블로그 포스팅:머신러닝 개요](https://mungdo-log.tistory.com/378)

[블로그 포스팅:지도학습](https://mungdo-log.tistory.com/379)

[깃허브 ipynb 파일](https://github.com/mungdo/multicam_ds/tree/main/12_MachineLearning/day1)

* list 형식 데이터 합치기 : `A.extend(B)`
* knn 
  * 모듈 불러오기 : `from sklearn.neighbors import KNeightborsClassifier`
  * 분류 : class 예측
    * `.predict(2차원 형식)` : 예측 결과값
  * 회귀 : 최근접 값의 평균을 결과값으로 예측
  * 훈련 적용 : `.fit(features, lable)`
  * 모델 평가(정확도 = 정확히 맞춘 갯수/전체 데이터 수) : `.score(features, label`
  * k 크기 지정 : `n_neighbors=K 개수` 인자 사용
  * knn 모델이 적용된 변수에 `.fit_X`는 `features`를 의미. `._Y`는 `label`을 의미.
* 모델 검증 - 홀드아웃 방식
  * train : test = 7:3, 9:1 ... 필요에 따라 비율 조정
  * 편향된 데이터 셋 분류 조심. shuffling 해야 함.
  * `from sklearn.model_selection import train_test_split` 모듈 사용
    * `stratify=` 인자 : 층화 표본 추출(class 등 계층 분리가 되어 있는 경우 균일하게 가져와). 초기값(none)은 무작위 표본 추출.
* 기준 맞추기 : 표준화 (Z-Score), 스케일링(scaling)
  * x축과 y축의 기준이 상이할 때, 상대적 거리를 반영하도록 함.
  * `(값 - 평균) / 표준편차` : 평균 0, 표준편차 1인 정규분포로 변환
  * 변환 후에 knn 재실시 하면 상대적인 거리를 반영한 예측 결과 도출
  
#
#


*<proDS 강의>*

1. [데이터 전처리](https://mungdo-log.tistory.com/380) : 생성, 정제
2. [확률 개념과 특징](https://mungdo-log.tistory.com/381)

#
#


---

## 🤭 20220303

__<머신러닝 : 지도학습 Decision Tree(회귀, 분류)>__

* dataframe 다루기
  * `apply` 함수 
```python
def label_name(label):
    if label == 0:
        name = iris_Tname[0]
    elif label == 1:
        name = iris_Tname[1]
    elif label == 2:
        name = iris_Tname[2]
    return name

iris_df2['label_name'] = iris_df2.apply(lambda x: label_name(x['label']), axis=1)
iris_df2 # iris_df2에 label_name이라는 column이 추가되어 있음.
```
#
* sklearn.datasets
  * `load_iris` 붓꽃 품종 분류
#
* DT
  * 모듈 불러오기 : `from sklearn.tree import DecisionTreeClassifier`
  * 분류 : label(class) 예측
    * [블로그 정리](https://mungdo-log.tistory.com/382)
  * 회귀 : *아직 수업 전*
#
* 모델 교차 검증 - k-fold 교차 검증
  * kXk개 폴드 세트 나눠서 k번 교차 검증함 
  1. `from sklearn.model_selection import KFold` : 수치 예측 모형에 사용
     * `kfold = KFOLD(n_splits=)`
     * `kfold.split(iris.data)`
     * iterable 객체로 for문 돌려 사용 `for train_index, val_index in kfold.split(iris.data):`
  2. `from sklearn.model_selection import StratifiedKFold`
     * 층화 k겹 교차검증 : 분류 문제 적용시 균열한 샘플링을 위해서 시행
     * `st_kfold = StratifiedKFold(n_splits=)`
     * `for train_index, val_index in st_kfold.split(iris_df, iris_df['label']):` : X, y를 인수로 입력 
     * 교차검증을 보다 간편하게 : `cross_val_score`
       * `score = cross_val_score(모델, X, y, scoring='accuracy', cv=3) `
#
* 교차 검증 + 하이퍼 파라미터(최적의 훈련 모델을 구현하기 위해 모델에 설정하는 변수. k값) 한번에 : `GridSearchCV` 클래스
```python
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=10)
dt_clf = DecisionTreeClassifier()
params = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}
grid_tree = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=3, refit=True, return_train_score=True)

grid_tree.fit(X_train, y_train)
scores_df = pd.Dataframe(grid_tree.cv_results_)

scores_df.columns() # ['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 
                # 'param_max_depth', 'param_min_samples_split', 'params', 'split0_test_score', 
                # 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 
                # 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 
                # 'mean_train_score', 'std_train_score']

grid_tree.best_params_ # 하이퍼 파라미터

# 최적의 파라미터 적용
best_dt = grid_tree.best_estimator_

# GridSearchCV 객체의 생성 파라미터로 refit=True로 설정된 경우(디폴트)
pred = best_dt.predict(X_test)
accuracy_score(y_test, pred)

```
#
* 예측 정확도 평가 `from sklearn.metrics import accuracy_score`
  * `accuracy_score(test_target, pred)`
#
* 데이터 전처리
  * 데이터 정제
    * 결측값 처리
      * 완전 제거법
      * 수작업으로 채워 넣기 or 특정값 사용
      * 핫덱 대체법 : 동일 조사의 유사한 관측값으로 얻은 자료로 대체
      * 평균값 사용 : 표준오차 과소추정 발생할 수 있음
      * 가능성이 높은 값으로 사용 (회귀분석, 보간법 등)
    * 이상치 처리
    * 잡음 제거
    * 데이터 형식 변환 = [데이터 인코딩](#데이터-인코딩--code-classlanguage-textlabelencodercode) (특정 분석 방법을 사용할 때 필요)
      * 문자열 -> 숫자로 코드화
      * 범주형자료 -> 수치화
  * 데이터 결합 (join)
  * 데이터 변환
    * Normalization (정규화)
    * scaling
  * 차원 축소
    - Feature selection
        - filter
        - wrapper
        - embedded
    - Feature extraction
        - PCA
        - SVD
        - FA
        - NMF

#### 데이터 인코딩 : `LabelEncoder`
```python
from sklearn.preprocessing import LabelEncoder # preprocession : 전처리에 필요한 모듈

items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']

encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)
labels # array([0, 1, 4, 5, 3, 3, 2, 2])

# 인코딩 전 원래의 값 확인 : encoder.classes_ 속성
encoder.classes_

# 인코딩된 값 디코딩
encoder.inverse_transform([1,4,5,0])
```
#
__원-핫 인코딩__ : 범주형 더미 변수 생성 (해당하는 컬럼에만 1)
1) OneHotEncoder 모듈 사용
```python
from sklearn.preprocessing import OneHotEncoder

# 1. LabelEncoder로 변환 (위에서 완료)
labels # array([0, 1, 4, 5, 3, 3, 2, 2])

# 2. 2차원 데이터로 변환
labels = labels.reshape(-1, 1) # -1 : 모든 행, 1: 열 하나
labels # array([[0],[1],[4],[5],[3],[3],[2],[2]])

# 3. 원-핫 인코딩 적용 
one_encoder = OneHotEncoder()
one_encoder.fit(labels)
one_labels = one_encoder.transform(labels)
print(one_labels) # 공간 절약을 위해서 0 값은 제외하고 보여줌

# 2차원 형태로 출력
one_labels.toarray()
# array([[1., 0., 0., 0., 0., 0.],
#        [0., 1., 0., 0., 0., 0.],
#        [0., 0., 0., 0., 1., 0.],
#        [0., 0., 0., 0., 0., 1.],
#        [0., 0., 0., 1., 0., 0.],
#        [0., 0., 0., 1., 0., 0.],
#        [0., 0., 1., 0., 0., 0.],
#        [0., 0., 1., 0., 0., 0.]])
```
#
2. pandas api `get_dummies()` 메서드 사용
```python
df = pd.DataFrame(items, columns=['item'])

# Pandas 데이터프레임을 NumPy 배열로 변환
pd.get_dummies(df).to_numpy()
# array([[1, 0, 0, 0, 0, 0],
#        [0, 1, 0, 0, 0, 0],
#        [0, 0, 0, 0, 1, 0],
#        [0, 0, 0, 0, 0, 1],
#        [0, 0, 0, 1, 0, 0],
#        [0, 0, 0, 1, 0, 0],
#        [0, 0, 1, 0, 0, 0],
#        [0, 0, 1, 0, 0, 0]], dtype=uint8)

pd.get_dummies(df) # 하단 이미지
```
![더미](one_hot_encoding.png)





#
#


*<proDS 강의>*

1. [데이터 전처리 2](https://mungdo-log.tistory.com/380) : 변환, 결합
2. [베이즈 정리](https://mungdo-log.tistory.com/381)


---

## 20220304


```toc
```

