---
emoji: ğŸŒˆ
title: "202203"
date: '2022-03-01 16:30:00'
author: mungdo
tags: til
categories: til
---


__ğŸ‘‹ ë§¤ì¼ ê³µë¶€ ê¸°ë¡__


## ğŸ¥º 20220301

__<ì•Œê³ ë¦¬ì¦˜>__

[ê¹ƒí—ˆë¸Œ ì—…ë¡œë“œ1](https://github.com/mungdo/mungdo/blob/main/algorithm/special%20lecture/8_%EA%B7%B8%EB%9E%98%ED%94%84%ED%83%90%EC%83%89.py)
[ê¹ƒí—ˆë¸Œ ì—…ë¡œë“œ2](https://github.com/mungdo/mungdo/blob/main/algorithm/special%20lecture/9_%EA%B7%B8%EB%9E%98%ED%94%84%ED%83%90%EC%83%89_%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4.py)

[ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…](https://mungdo-log.tistory.com/377)

* ê·¸ë˜í”„ íƒìƒ‰
    * DFS
    * BFS



---

## âš™ï¸ 20220302

__<ë¨¸ì‹ ëŸ¬ë‹ : ì§€ë„í•™ìŠµ knn(íšŒê·€, ë¶„ë¥˜)>__

[ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…:ë¨¸ì‹ ëŸ¬ë‹ ê°œìš”](https://mungdo-log.tistory.com/378)

[ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…:ì§€ë„í•™ìŠµ](https://mungdo-log.tistory.com/379)

[ê¹ƒí—ˆë¸Œ ipynb íŒŒì¼](https://github.com/mungdo/multicam_ds/tree/main/12_MachineLearning/day1)

* list í˜•ì‹ ë°ì´í„° í•©ì¹˜ê¸° : `A.extend(B)`
* knn 
  * ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° : `from sklearn.neighbors import KNeightborsClassifier`
  * ë¶„ë¥˜ : class ì˜ˆì¸¡
    * `.predict(2ì°¨ì› í˜•ì‹)` : ì˜ˆì¸¡ ê²°ê³¼ê°’
  * íšŒê·€ : ìµœê·¼ì ‘ ê°’ì˜ í‰ê· ì„ ê²°ê³¼ê°’ìœ¼ë¡œ ì˜ˆì¸¡
  * í›ˆë ¨ ì ìš© : `.fit(features, lable)`
  * ëª¨ë¸ í‰ê°€(ì •í™•ë„ = ì •í™•íˆ ë§ì¶˜ ê°¯ìˆ˜/ì „ì²´ ë°ì´í„° ìˆ˜) : `.score(features, label`
  * k í¬ê¸° ì§€ì • : `n_neighbors=K ê°œìˆ˜` ì¸ì ì‚¬ìš©
  * knn ëª¨ë¸ì´ ì ìš©ëœ ë³€ìˆ˜ì— `.fit_X`ëŠ” `features`ë¥¼ ì˜ë¯¸. `._Y`ëŠ” `label`ì„ ì˜ë¯¸.
* ëª¨ë¸ ê²€ì¦ - í™€ë“œì•„ì›ƒ ë°©ì‹
  * train : test = 7:3, 9:1 ... í•„ìš”ì— ë”°ë¼ ë¹„ìœ¨ ì¡°ì •
  * í¸í–¥ëœ ë°ì´í„° ì…‹ ë¶„ë¥˜ ì¡°ì‹¬. shuffling í•´ì•¼ í•¨.
  * `from sklearn.model_selection import train_test_split` ëª¨ë“ˆ ì‚¬ìš©
    * `stratify=` ì¸ì : ì¸µí™” í‘œë³¸ ì¶”ì¶œ(class ë“± ê³„ì¸µ ë¶„ë¦¬ê°€ ë˜ì–´ ìˆëŠ” ê²½ìš° ê· ì¼í•˜ê²Œ ê°€ì ¸ì™€). ì´ˆê¸°ê°’(none)ì€ ë¬´ì‘ìœ„ í‘œë³¸ ì¶”ì¶œ.
* ê¸°ì¤€ ë§ì¶”ê¸° : í‘œì¤€í™” (Z-Score), ìŠ¤ì¼€ì¼ë§(scaling)
  * xì¶•ê³¼ yì¶•ì˜ ê¸°ì¤€ì´ ìƒì´í•  ë•Œ, ìƒëŒ€ì  ê±°ë¦¬ë¥¼ ë°˜ì˜í•˜ë„ë¡ í•¨.
  * `(ê°’ - í‰ê· ) / í‘œì¤€í¸ì°¨` : í‰ê·  0, í‘œì¤€í¸ì°¨ 1ì¸ ì •ê·œë¶„í¬ë¡œ ë³€í™˜
  * ë³€í™˜ í›„ì— knn ì¬ì‹¤ì‹œ í•˜ë©´ ìƒëŒ€ì ì¸ ê±°ë¦¬ë¥¼ ë°˜ì˜í•œ ì˜ˆì¸¡ ê²°ê³¼ ë„ì¶œ
  
#
#


*<proDS ê°•ì˜>*

1. [ë°ì´í„° ì „ì²˜ë¦¬](https://mungdo-log.tistory.com/380) : ìƒì„±, ì •ì œ
2. [í™•ë¥  ê°œë…ê³¼ íŠ¹ì§•](https://mungdo-log.tistory.com/381)

#
#


---

## ğŸ¤­ 20220303

__<ë¨¸ì‹ ëŸ¬ë‹ : ì§€ë„í•™ìŠµ Decision Tree(íšŒê·€, ë¶„ë¥˜)>__

* dataframe ë‹¤ë£¨ê¸°
  * `apply` í•¨ìˆ˜ 
```python
def label_name(label):
    if label == 0:
        name = iris_Tname[0]
    elif label == 1:
        name = iris_Tname[1]
    elif label == 2:
        name = iris_Tname[2]
    return name

iris_df2['label_name'] = iris_df2.apply(lambda x: label_name(x['label']), axis=1)
iris_df2 # iris_df2ì— label_nameì´ë¼ëŠ” columnì´ ì¶”ê°€ë˜ì–´ ìˆìŒ.
```
#
* sklearn.datasets
  * `load_iris` ë¶“ê½ƒ í’ˆì¢… ë¶„ë¥˜
#
* DT
  * ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° : `from sklearn.tree import DecisionTreeClassifier`
  * ë¶„ë¥˜ : label(class) ì˜ˆì¸¡
    * [ë¸”ë¡œê·¸ ì •ë¦¬](https://mungdo-log.tistory.com/382)
  * íšŒê·€ : *ì•„ì§ ìˆ˜ì—… ì „*
#
* ëª¨ë¸ êµì°¨ ê²€ì¦ - k-fold êµì°¨ ê²€ì¦
  * kXkê°œ í´ë“œ ì„¸íŠ¸ ë‚˜ëˆ ì„œ kë²ˆ êµì°¨ ê²€ì¦í•¨ 
  1. `from sklearn.model_selection import KFold` : ìˆ˜ì¹˜ ì˜ˆì¸¡ ëª¨í˜•ì— ì‚¬ìš©
     * `kfold = KFOLD(n_splits=)`
     * `kfold.split(iris.data)`
     * iterable ê°ì²´ë¡œ forë¬¸ ëŒë ¤ ì‚¬ìš© `for train_index, val_index in kfold.split(iris.data):`
  2. `from sklearn.model_selection import StratifiedKFold`
     * ì¸µí™” kê²¹ êµì°¨ê²€ì¦ : ë¶„ë¥˜ ë¬¸ì œ ì ìš©ì‹œ ê· ì—´í•œ ìƒ˜í”Œë§ì„ ìœ„í•´ì„œ ì‹œí–‰
     * `st_kfold = StratifiedKFold(n_splits=)`
     * `for train_index, val_index in st_kfold.split(iris_df, iris_df['label']):` : X, yë¥¼ ì¸ìˆ˜ë¡œ ì…ë ¥ 
     * êµì°¨ê²€ì¦ì„ ë³´ë‹¤ ê°„í¸í•˜ê²Œ : `cross_val_score`
       * `score = cross_val_score(ëª¨ë¸, X, y, scoring='accuracy', cv=3) `
#
* êµì°¨ ê²€ì¦ + í•˜ì´í¼ íŒŒë¼ë¯¸í„°(ìµœì ì˜ í›ˆë ¨ ëª¨ë¸ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ ëª¨ë¸ì— ì„¤ì •í•˜ëŠ” ë³€ìˆ˜. kê°’) í•œë²ˆì— : `GridSearchCV` í´ë˜ìŠ¤
```python
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=10)
dt_clf = DecisionTreeClassifier()
params = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}
grid_tree = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=3, refit=True, return_train_score=True)

grid_tree.fit(X_train, y_train)
scores_df = pd.Dataframe(grid_tree.cv_results_)

scores_df.columns() # ['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 
                # 'param_max_depth', 'param_min_samples_split', 'params', 'split0_test_score', 
                # 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 
                # 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 
                # 'mean_train_score', 'std_train_score']

grid_tree.best_params_ # í•˜ì´í¼ íŒŒë¼ë¯¸í„°

# ìµœì ì˜ íŒŒë¼ë¯¸í„° ì ìš©
best_dt = grid_tree.best_estimator_

# GridSearchCV ê°ì²´ì˜ ìƒì„± íŒŒë¼ë¯¸í„°ë¡œ refit=Trueë¡œ ì„¤ì •ëœ ê²½ìš°(ë””í´íŠ¸)
pred = best_dt.predict(X_test)
accuracy_score(y_test, pred)

```
#
* ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€ `from sklearn.metrics import accuracy_score`
  * `accuracy_score(test_target, pred)`
#
* ë°ì´í„° ì „ì²˜ë¦¬
  * ë°ì´í„° ì •ì œ
    * ê²°ì¸¡ê°’ ì²˜ë¦¬
      * ì™„ì „ ì œê±°ë²•
      * ìˆ˜ì‘ì—…ìœ¼ë¡œ ì±„ì›Œ ë„£ê¸° or íŠ¹ì •ê°’ ì‚¬ìš©
      * í•«ë± ëŒ€ì²´ë²• : ë™ì¼ ì¡°ì‚¬ì˜ ìœ ì‚¬í•œ ê´€ì¸¡ê°’ìœ¼ë¡œ ì–»ì€ ìë£Œë¡œ ëŒ€ì²´
      * í‰ê· ê°’ ì‚¬ìš© : í‘œì¤€ì˜¤ì°¨ ê³¼ì†Œì¶”ì • ë°œìƒí•  ìˆ˜ ìˆìŒ
      * ê°€ëŠ¥ì„±ì´ ë†’ì€ ê°’ìœ¼ë¡œ ì‚¬ìš© (íšŒê·€ë¶„ì„, ë³´ê°„ë²• ë“±)
    * ì´ìƒì¹˜ ì²˜ë¦¬
    * ì¡ìŒ ì œê±°
    * ë°ì´í„° í˜•ì‹ ë³€í™˜ = [ë°ì´í„° ì¸ì½”ë”©](#ë°ì´í„°-ì¸ì½”ë”©--code-classlanguage-textlabelencodercode) (íŠ¹ì • ë¶„ì„ ë°©ë²•ì„ ì‚¬ìš©í•  ë•Œ í•„ìš”)
      * ë¬¸ìì—´ -> ìˆ«ìë¡œ ì½”ë“œí™”
      * ë²”ì£¼í˜•ìë£Œ -> ìˆ˜ì¹˜í™”
  * ë°ì´í„° ê²°í•© (join)
  * ë°ì´í„° ë³€í™˜
    * Normalization (ì •ê·œí™”)
    * scaling
  * ì°¨ì› ì¶•ì†Œ
    - Feature selection
        - filter
        - wrapper
        - embedded
    - Feature extraction
        - PCA
        - SVD
        - FA
        - NMF

#### ë°ì´í„° ì¸ì½”ë”© : `LabelEncoder`
```python
from sklearn.preprocessing import LabelEncoder # preprocession : ì „ì²˜ë¦¬ì— í•„ìš”í•œ ëª¨ë“ˆ

items = ['TV', 'ëƒ‰ì¥ê³ ', 'ì „ìë Œì§€', 'ì»´í“¨í„°', 'ì„ í’ê¸°', 'ì„ í’ê¸°', 'ë¯¹ì„œ', 'ë¯¹ì„œ']

encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)
labels # array([0, 1, 4, 5, 3, 3, 2, 2])

# ì¸ì½”ë”© ì „ ì›ë˜ì˜ ê°’ í™•ì¸ : encoder.classes_ ì†ì„±
encoder.classes_

# ì¸ì½”ë”©ëœ ê°’ ë””ì½”ë”©
encoder.inverse_transform([1,4,5,0])
```
#
__ì›-í•« ì¸ì½”ë”©__ : ë²”ì£¼í˜• ë”ë¯¸ ë³€ìˆ˜ ìƒì„± (í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ì—ë§Œ 1)
1) OneHotEncoder ëª¨ë“ˆ ì‚¬ìš©
```python
from sklearn.preprocessing import OneHotEncoder

# 1. LabelEncoderë¡œ ë³€í™˜ (ìœ„ì—ì„œ ì™„ë£Œ)
labels # array([0, 1, 4, 5, 3, 3, 2, 2])

# 2. 2ì°¨ì› ë°ì´í„°ë¡œ ë³€í™˜
labels = labels.reshape(-1, 1) # -1 : ëª¨ë“  í–‰, 1: ì—´ í•˜ë‚˜
labels # array([[0],[1],[4],[5],[3],[3],[2],[2]])

# 3. ì›-í•« ì¸ì½”ë”© ì ìš© 
one_encoder = OneHotEncoder()
one_encoder.fit(labels)
one_labels = one_encoder.transform(labels)
print(one_labels) # ê³µê°„ ì ˆì•½ì„ ìœ„í•´ì„œ 0 ê°’ì€ ì œì™¸í•˜ê³  ë³´ì—¬ì¤Œ

# 2ì°¨ì› í˜•íƒœë¡œ ì¶œë ¥
one_labels.toarray()
# array([[1., 0., 0., 0., 0., 0.],
#        [0., 1., 0., 0., 0., 0.],
#        [0., 0., 0., 0., 1., 0.],
#        [0., 0., 0., 0., 0., 1.],
#        [0., 0., 0., 1., 0., 0.],
#        [0., 0., 0., 1., 0., 0.],
#        [0., 0., 1., 0., 0., 0.],
#        [0., 0., 1., 0., 0., 0.]])
```
#
2. pandas api `get_dummies()` ë©”ì„œë“œ ì‚¬ìš©
```python
df = pd.DataFrame(items, columns=['item'])

# Pandas ë°ì´í„°í”„ë ˆì„ì„ NumPy ë°°ì—´ë¡œ ë³€í™˜
pd.get_dummies(df).to_numpy()
# array([[1, 0, 0, 0, 0, 0],
#        [0, 1, 0, 0, 0, 0],
#        [0, 0, 0, 0, 1, 0],
#        [0, 0, 0, 0, 0, 1],
#        [0, 0, 0, 1, 0, 0],
#        [0, 0, 0, 1, 0, 0],
#        [0, 0, 1, 0, 0, 0],
#        [0, 0, 1, 0, 0, 0]], dtype=uint8)

pd.get_dummies(df) # í•˜ë‹¨ ì´ë¯¸ì§€
```
![ë”ë¯¸](one_hot_encoding.png)





#
#


*<proDS ê°•ì˜>*

1. [ë°ì´í„° ì „ì²˜ë¦¬ 2](https://mungdo-log.tistory.com/380) : ë³€í™˜, ê²°í•©
2. [ë² ì´ì¦ˆ ì •ë¦¬](https://mungdo-log.tistory.com/381)


---

## ğŸ˜µâ€ğŸ’« 20220304

__<ë¨¸ì‹ ëŸ¬ë‹ ìˆœì„œ>__
1. ë°ì´í„° ì „ì²˜ë¦¬ 
   1. EDA : ë¶„í¬ í™•ì¸
   2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ : `isnull` `fillna`
   3. êµ¬ê°„í™” (binning) 
   4. ì¸ì½”ë”© : ë¬¸ìì—´ -> ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
   5. (í•„ìš” ì—†ëŠ” ì—´) ì‚­ì œ
2. í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¥˜ `model_selection > train_test_split`
3. ëª¨ë¸ì„ í™œìš©í•œ í•™ìŠµ `fit` / ì˜ˆì¸¡ `predict` / í‰ê°€(ì •í™•ë„) `accuracy_score()`
4. êµì°¨ ê²€ì¦ì„ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ `model_selection`
   1. `cross_val_score()` : stratified Kfold êµì°¨ê²€ì¦ ë¹ ë¥´ê²Œ ìˆ˜í–‰
   2. `GridSearchCV` : í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹

* ëª¨ë¸ ë§Œë“¤ê¸° : `BaseEstimator` 

#

__<í‰ê°€ ì§€í‘œ>__

> ì •í™•ë„ë§Œ ì‚¬ìš©í•´ ê²€ì¦í•´ë´¤ëŠ”ë°, ê·¸ ì™¸ì—ë„ ì—¬ëŸ¬ í‰ê°€ ì§€í‘œê°€ ìˆìŒ

* ë¶„ë¥˜ ëª¨ë¸ì˜ í‰ê°€ ì§€í‘œ : ë²”ì£¼í˜• ë°ì´í„° ì˜ˆì¸¡
  - ì •í™•ë„(Accuracy)
  - ì¬í˜„ìœ¨(Recall)
  - ì •ë°€ë„(Precision)
  - F1 measure ë“± ...

* íšŒê·€ ëª¨ë¸ì˜ í‰ê°€ ì§€í‘œ : ìˆ˜ì¹˜í˜• ë°ì´í„° ì˜ˆì¸¡
  - MSE(Mean Square Error)
  - RMSE(Root Mean Square Error)
  - MAE(Mean Absolute Error)
  - MAPE(Mean Absolute Percentage Error)
  - $ R^2 $

---


## ğŸ¤¨ 20220305

__<ì•Œê³ ë¦¬ì¦˜>__

> ì´ê²ƒì´ ì·¨ì—…ì„ ìœ„í•œ ì½”ë”©í…ŒìŠ¤íŠ¸ë‹¤

* ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜
  * [ë¬¸ìì—´ ë’¤ì§‘ê¸°](https://github.com/mungdo/mungdo/blob/main/algorithm/thisiscodingtest/%EA%B7%B8%EB%A6%AC%EB%94%94/%EB%AC%B8%EC%9E%90%EC%97%B4_%EB%92%A4%EC%A7%91%EA%B8%B0.py)
  * [ëª¨í—˜ê°€ ê¸¸ë“œ](https://github.com/mungdo/mungdo/blob/main/algorithm/thisiscodingtest/%EA%B7%B8%EB%A6%AC%EB%94%94/%EB%AA%A8%ED%97%98%EA%B0%80_%EA%B8%B8%EB%93%9C.py)
  * [ë§Œë“¤ ìˆ˜ ì—†ëŠ” ê¸ˆì•¡](https://github.com/mungdo/mungdo/blob/main/algorithm/thisiscodingtest/%EA%B7%B8%EB%A6%AC%EB%94%94/%EB%A7%8C%EB%93%A4_%EC%88%98_%EC%97%86%EB%8A%94_%EA%B8%88%EC%95%A1.py)

#

---

#

## ğŸŒ 20220307


__<ë¨¸ì‹ ëŸ¬ë‹ : ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ>__

|     |          | ì˜ˆì¸¡       | ì˜ˆì¸¡       |
|-----|----------|----------|----------|
|     |          | Positive | Negative |
| ì‹¤ì œ  | Positive | TP       | FN       |
| ì‹¤ì œ  | Negative | FP       | TN       |

1. ì •í™•ë„ : `accuracy_score(y_test, pred)`
   * (TP + TN) / (TP + FN + FP + TN)
2. ì •ë°€ë„ : `precision_score(y_test, pred)`
   * TP / (TP + FN)
3. ì¬í˜„ìœ¨ : `recall_score(y_test, pred)`
   * TP / (TP + FN)
4. f1 score : `f1_score(y_test, pred)`
   * ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· 
5. G measure : $G = \sqrt{Precision Ã— Recall}$
6. ROC curve : ë¯¼ê°ë„ì™€ íŠ¹ì´ë„ ë³„ ê·¸ë˜í”„
   * ë¯¼ê°ë„ : TP / (TP + FP)
   * íŠ¹ì´ë„ : TN / (FP + TN)
   * ë¯¼ê°ë„ì™€ íŠ¹ì´ë„ ì°¨ì´ê°€ í¬ë‹¤ë©´ ì˜¬ë°”ë¥¸ ë°©ì‹ì´ ì•„ë‹˜.
   * AUC(ROU curve ì•„ë˜ ë©´ì )ê°€ 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì¢‹ì€ ëª¨í˜•.


# 

---

#

## ğŸ’¦ 20220308






```toc
```

