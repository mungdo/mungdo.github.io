---
emoji: 🌈
title: "202203"
date: '2022-03-01 16:30:00'
author: mungdo
tags: til
categories: til
---


__👋 매일 공부 기록__


## 🥺 20220301

__<알고리즘>__

[깃허브 업로드1](https://github.com/mungdo/mungdo/blob/main/algorithm/special%20lecture/8_%EA%B7%B8%EB%9E%98%ED%94%84%ED%83%90%EC%83%89.py)
[깃허브 업로드2](https://github.com/mungdo/mungdo/blob/main/algorithm/special%20lecture/9_%EA%B7%B8%EB%9E%98%ED%94%84%ED%83%90%EC%83%89_%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4.py)

[블로그 포스팅](https://mungdo-log.tistory.com/377)

* 그래프 탐색
    * DFS
    * BFS



---

## ⚙️ 20220302

__<머신러닝 : 지도학습 knn(회귀, 분류)>__

[블로그 포스팅:머신러닝 개요](https://mungdo-log.tistory.com/378)

[블로그 포스팅:지도학습](https://mungdo-log.tistory.com/379)

[깃허브 ipynb 파일](https://github.com/mungdo/multicam_ds/tree/main/12_MachineLearning/day1)

* list 형식 데이터 합치기 : `A.extend(B)`
* knn 
  * 모듈 불러오기 : `from sklearn.neighbors import KNeightborsClassifier`
  * 분류 : class 예측
    * `.predict(2차원 형식)` : 예측 결과값
  * 회귀 : 최근접 값의 평균을 결과값으로 예측
  * 훈련 적용 : `.fit(features, lable)`
  * 모델 평가(정확도 = 정확히 맞춘 갯수/전체 데이터 수) : `.score(features, label`
  * k 크기 지정 : `n_neighbors=K 개수` 인자 사용
  * knn 모델이 적용된 변수에 `.fit_X`는 `features`를 의미. `._Y`는 `label`을 의미.
* 모델 검증 - 홀드아웃 방식
  * train : test = 7:3, 9:1 ... 필요에 따라 비율 조정
  * 편향된 데이터 셋 분류 조심. shuffling 해야 함.
  * `from sklearn.model_selection import train_test_split` 모듈 사용
    * `stratify=` 인자 : 층화 표본 추출(class 등 계층 분리가 되어 있는 경우 균일하게 가져와). 초기값(none)은 무작위 표본 추출.
* 기준 맞추기 : 표준화 (Z-Score), 스케일링(scaling)
  * x축과 y축의 기준이 상이할 때, 상대적 거리를 반영하도록 함.
  * `(값 - 평균) / 표준편차` : 평균 0, 표준편차 1인 정규분포로 변환
  * 변환 후에 knn 재실시 하면 상대적인 거리를 반영한 예측 결과 도출
  
#
#


*<proDS 강의>*

1. [데이터 전처리](https://mungdo-log.tistory.com/380) : 생성, 정제
2. [확률 개념과 특징](https://mungdo-log.tistory.com/381)

#
#


---

## 🤭 20220303

__<머신러닝 : 지도학습 Decision Tree(회귀, 분류)>__

* dataframe 다루기
  * `apply` 함수 
```python
def label_name(label):
    if label == 0:
        name = iris_Tname[0]
    elif label == 1:
        name = iris_Tname[1]
    elif label == 2:
        name = iris_Tname[2]
    return name

iris_df2['label_name'] = iris_df2.apply(lambda x: label_name(x['label']), axis=1)
iris_df2 # iris_df2에 label_name이라는 column이 추가되어 있음.
```
#
* sklearn.datasets
  * `load_iris` 붓꽃 품종 분류
#
* DT
  * 모듈 불러오기 : `from sklearn.tree import DecisionTreeClassifier`
  * 분류 : label(class) 예측
    * [블로그 정리](https://mungdo-log.tistory.com/382)
  * 회귀 : *아직 수업 전*
#
* 모델 교차 검증 - k-fold 교차 검증
  * kXk개 폴드 세트 나눠서 k번 교차 검증함 
  1. `from sklearn.model_selection import KFold` : 수치 예측 모형에 사용
     * `kfold = KFOLD(n_splits=)`
     * `kfold.split(iris.data)`
     * iterable 객체로 for문 돌려 사용 `for train_index, val_index in kfold.split(iris.data):`
  2. `from sklearn.model_selection import StratifiedKFold`
     * 층화 k겹 교차검증 : 분류 문제 적용시 균열한 샘플링을 위해서 시행
     * `st_kfold = StratifiedKFold(n_splits=)`
     * `for train_index, val_index in st_kfold.split(iris_df, iris_df['label']):` : X, y를 인수로 입력 
     * 교차검증을 보다 간편하게 : `cross_val_score`
       * `score = cross_val_score(모델, X, y, scoring='accuracy', cv=3) `
#
* 교차 검증 + 하이퍼 파라미터(최적의 훈련 모델을 구현하기 위해 모델에 설정하는 변수. k값) 한번에 : `GridSearchCV` 클래스
```python
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=10)
dt_clf = DecisionTreeClassifier()
params = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}
grid_tree = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=3, refit=True, return_train_score=True)

grid_tree.fit(X_train, y_train)
scores_df = pd.Dataframe(grid_tree.cv_results_)

scores_df.columns() # ['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 
                # 'param_max_depth', 'param_min_samples_split', 'params', 'split0_test_score', 
                # 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 
                # 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 
                # 'mean_train_score', 'std_train_score']

grid_tree.best_params_ # 하이퍼 파라미터

# 최적의 파라미터 적용
best_dt = grid_tree.best_estimator_

# GridSearchCV 객체의 생성 파라미터로 refit=True로 설정된 경우(디폴트)
pred = best_dt.predict(X_test)
accuracy_score(y_test, pred)

```
#
* 예측 정확도 평가 `from sklearn.metrics import accuracy_score`
  * `accuracy_score(test_target, pred)`
#
* 데이터 전처리
  * 데이터 정제
    * 결측값 처리
      * 완전 제거법
      * 수작업으로 채워 넣기 or 특정값 사용
      * 핫덱 대체법 : 동일 조사의 유사한 관측값으로 얻은 자료로 대체
      * 평균값 사용 : 표준오차 과소추정 발생할 수 있음
      * 가능성이 높은 값으로 사용 (회귀분석, 보간법 등)
    * 이상치 처리
    * 잡음 제거
    * 데이터 형식 변환 = [데이터 인코딩](#데이터-인코딩--code-classlanguage-textlabelencodercode) (특정 분석 방법을 사용할 때 필요)
      * 문자열 -> 숫자로 코드화
      * 범주형자료 -> 수치화
  * 데이터 결합 (join)
  * 데이터 변환
    * Normalization (정규화)
    * scaling
  * 차원 축소
    - Feature selection
        - filter
        - wrapper
        - embedded
    - Feature extraction
        - PCA
        - SVD
        - FA
        - NMF

#### 데이터 인코딩 : `LabelEncoder`
```python
from sklearn.preprocessing import LabelEncoder # preprocession : 전처리에 필요한 모듈

items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']

encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)
labels # array([0, 1, 4, 5, 3, 3, 2, 2])

# 인코딩 전 원래의 값 확인 : encoder.classes_ 속성
encoder.classes_

# 인코딩된 값 디코딩
encoder.inverse_transform([1,4,5,0])
```
#
__원-핫 인코딩__ : 범주형 더미 변수 생성 (해당하는 컬럼에만 1)
1) OneHotEncoder 모듈 사용
```python
from sklearn.preprocessing import OneHotEncoder

# 1. LabelEncoder로 변환 (위에서 완료)
labels # array([0, 1, 4, 5, 3, 3, 2, 2])

# 2. 2차원 데이터로 변환
labels = labels.reshape(-1, 1) # -1 : 모든 행, 1: 열 하나
labels # array([[0],[1],[4],[5],[3],[3],[2],[2]])

# 3. 원-핫 인코딩 적용 
one_encoder = OneHotEncoder()
one_encoder.fit(labels)
one_labels = one_encoder.transform(labels)
print(one_labels) # 공간 절약을 위해서 0 값은 제외하고 보여줌

# 2차원 형태로 출력
one_labels.toarray()
# array([[1., 0., 0., 0., 0., 0.],
#        [0., 1., 0., 0., 0., 0.],
#        [0., 0., 0., 0., 1., 0.],
#        [0., 0., 0., 0., 0., 1.],
#        [0., 0., 0., 1., 0., 0.],
#        [0., 0., 0., 1., 0., 0.],
#        [0., 0., 1., 0., 0., 0.],
#        [0., 0., 1., 0., 0., 0.]])
```
#
2. pandas api `get_dummies()` 메서드 사용
```python
df = pd.DataFrame(items, columns=['item'])

# Pandas 데이터프레임을 NumPy 배열로 변환
pd.get_dummies(df).to_numpy()
# array([[1, 0, 0, 0, 0, 0],
#        [0, 1, 0, 0, 0, 0],
#        [0, 0, 0, 0, 1, 0],
#        [0, 0, 0, 0, 0, 1],
#        [0, 0, 0, 1, 0, 0],
#        [0, 0, 0, 1, 0, 0],
#        [0, 0, 1, 0, 0, 0],
#        [0, 0, 1, 0, 0, 0]], dtype=uint8)

pd.get_dummies(df) # 하단 이미지
```
![더미](one_hot_encoding.png)





#
#


*<proDS 강의>*

1. [데이터 전처리 2](https://mungdo-log.tistory.com/380) : 변환, 결합
2. [베이즈 정리](https://mungdo-log.tistory.com/381)


---

## 😵‍💫 20220304

__<머신러닝 순서>__
1. 데이터 전처리 
   1. EDA : 분포 확인
   2. 결측치 처리 : `isnull` `fillna`
   3. 구간화 (binning) 
   4. 인코딩 : 문자열 -> 숫자형으로 변환
   5. (필요 없는 열) 삭제
2. 학습 데이터와 테스트 데이터 분류 `model_selection > train_test_split`
3. 모델을 활용한 학습 `fit` / 예측 `predict` / 평가(정확도) `accuracy_score()`
4. 교차 검증을 통한 모델 성능 향상 `model_selection`
   1. `cross_val_score()` : stratified Kfold 교차검증 빠르게 수행
   2. `GridSearchCV` : 하이퍼 파라미터 튜닝

* 모델 만들기 : `BaseEstimator` 

#

__<평가 지표>__

> 정확도만 사용해 검증해봤는데, 그 외에도 여러 평가 지표가 있음

* 분류 모델의 평가 지표 : 범주형 데이터 예측
  - 정확도(Accuracy)
  - 재현율(Recall)
  - 정밀도(Precision)
  - F1 measure 등 ...

* 회귀 모델의 평가 지표 : 수치형 데이터 예측
  - MSE(Mean Square Error)
  - RMSE(Root Mean Square Error)
  - MAE(Mean Absolute Error)
  - MAPE(Mean Absolute Percentage Error)
  - $ R^2 $

---


## 🤨 20220305

__<알고리즘>__

> 이것이 취업을 위한 코딩테스트다

* 그리디 알고리즘
  * [문자열 뒤집기](https://github.com/mungdo/mungdo/blob/main/algorithm/thisiscodingtest/%EA%B7%B8%EB%A6%AC%EB%94%94/%EB%AC%B8%EC%9E%90%EC%97%B4_%EB%92%A4%EC%A7%91%EA%B8%B0.py)
  * [모험가 길드](https://github.com/mungdo/mungdo/blob/main/algorithm/thisiscodingtest/%EA%B7%B8%EB%A6%AC%EB%94%94/%EB%AA%A8%ED%97%98%EA%B0%80_%EA%B8%B8%EB%93%9C.py)
  * [만들 수 없는 금액](https://github.com/mungdo/mungdo/blob/main/algorithm/thisiscodingtest/%EA%B7%B8%EB%A6%AC%EB%94%94/%EB%A7%8C%EB%93%A4_%EC%88%98_%EC%97%86%EB%8A%94_%EA%B8%88%EC%95%A1.py)

#

---

#

## 🌝 20220307


__<머신러닝 : 분류 모델의 성능 평가 지표>__

|     |          | 예측       | 예측       |
|-----|----------|----------|----------|
|     |          | Positive | Negative |
| 실제  | Positive | TP       | FN       |
| 실제  | Negative | FP       | TN       |

1. 정확도 : `accuracy_score(y_test, pred)`
   * (TP + TN) / (TP + FN + FP + TN)
2. 정밀도 : `precision_score(y_test, pred)`
   * TP / (TP + FN)
3. 재현율 : `recall_score(y_test, pred)`
   * TP / (TP + FN)
4. f1 score : `f1_score(y_test, pred)`
   * 정확도와 재현율의 조화평균
5. G measure : $G = \sqrt{Precision × Recall}$
6. ROC curve : 민감도와 특이도 별 그래프
   * 민감도 : TP / (TP + FP)
   * 특이도 : TN / (FP + TN)
   * 민감도와 특이도 차이가 크다면 올바른 방식이 아님.
   * AUC(ROU curve 아래 면적)가 1에 가까울 수록 좋은 모형.


# 

---

#

## 💦 20220308






```toc
```

