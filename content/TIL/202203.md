---
emoji: 🌈
title: "202203"
date: '2022-03-01 16:30:00'
author: mungdo
tags: til
categories: til
---


__👋 매일 공부 기록__


## 🥺 20220301

__<알고리즘>__

* 그래프 탐색
    * DFS
    * BFS


---

## ⚙️ 20220302

__<머신러닝 : 지도학습 knn(회귀, 분류)>__

[블로그 포스팅:머신러닝 개요](https://mungdo-log.tistory.com/378)

[블로그 포스팅:지도학습](https://mungdo-log.tistory.com/379)

[깃허브 ipynb 파일](https://github.com/mungdo/multicam_ds/tree/main/12_MachineLearning/day1)


[머신러닝 실습 코드 연습]
* list 형식 데이터 합치기 : `A.extend(B)`
* knn 
  * 모듈 불러오기 : `from sklearn.neighbors import KNeightborsClassifier`
  * 분류 : class 예측
    * `.predict(2차원 형식)` : 예측 결과값
  * 회귀 : 최근접 값의 평균을 결과값으로 예측
  * 훈련 적용 : `.fit(features, lable)`
  * 모델 평가(정확도 = 정확히 맞춘 갯수/전체 데이터 수) : `.score(features, label`
  * k 크기 지정 : `n_neighbors=K 개수` 인자 사용
  * knn 모델이 적용된 변수에 `.fit_X`는 `features`를 의미. `._Y`는 `label`을 의미.
* 모델 검증 - 홀드아웃 방식
  * train : test = 7:3, 9:1 ... 필요에 따라 비율 조정
  * 편향된 데이터 셋 분류 조심. shuffling 해야 함.
  * `from sklearn.model_selection import train_test_split` 모듈 사용
    * `stratify=` 인자 : 층화 표본 추출(class 등 계층 분리가 되어 있는 경우 균일하게 가져와). 초기값(none)은 무작위 표본 추출.
* 기준 맞추기 : 표준화 (Z-Score), 스케일링(scaling)
  * x축과 y축의 기준이 상이할 때, 상대적 거리를 반영하도록 함.
  * `(값 - 평균) / 표준편차` : 평균 0, 표준편차 1인 정규분포로 변환
  * 변환 후에 knn 재실시 하면 상대적인 거리를 반영한 예측 결과 도출
  


__<알고리즘>__

```toc
```

